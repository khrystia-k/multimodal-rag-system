{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scraping_urls/ghost_apis.json', 'r') as file:\n",
    "    ghost_apis = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scraping_urls/tag_urls.json', 'r') as file:\n",
    "    tag_urls = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(post):\n",
    "    return({'title' : post['title'], \n",
    "                    'slug':post['slug'], \n",
    "                    'feature_image':post['feature_image'], \n",
    "                    'link': f'https://www.deeplearning.ai/the-batch/{post[\"slug\"]}' })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_Ghost_API(url : str):\n",
    "    pg_num = 1 \n",
    "    titles = []\n",
    "    while True:\n",
    "        response = requests.get(f'{url}{pg_num}')\n",
    "        data = response.json()\n",
    "        posts_info = data['posts']\n",
    "\n",
    "        if len(posts_info) == 0:\n",
    "            break\n",
    "\n",
    "        for post in posts_info:\n",
    "            titles.append(extract(post))\n",
    "        pg_num += 1\n",
    "    \n",
    "    return titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_issues(base_url : str, max_arcticles_num):\n",
    "    \n",
    "    pg_num = 1\n",
    "    titles_issues = []\n",
    "    not_found = {'notFound': True}\n",
    "  \n",
    "    while True:\n",
    "\n",
    "        response = requests.get(base_url.format(pg_num, pg_num))\n",
    "        data = response.json()\n",
    "\n",
    "        if pg_num > max_arcticles_num:\n",
    "            break\n",
    "\n",
    "        if data == not_found:\n",
    "            pg_num += 1\n",
    "            continue\n",
    "        \n",
    "        post = data['pageProps']['cmsData']['post']\n",
    "\n",
    "        titles_issues.append(extract(post))\n",
    "        pg_num += 1\n",
    "\n",
    "    return titles_issues\n",
    "\n",
    "\n",
    "def scrape_letters(base_url : str):\n",
    "    pg_num = 1\n",
    "    titles_letters = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.get(base_url.format(pg_num, pg_num))\n",
    "        data = response.json()\n",
    "        posts_info = data['pageProps']['posts'] \n",
    "\n",
    "        if len(posts_info) == 0:\n",
    "            break\n",
    "\n",
    "        for post in posts_info:\n",
    "            titles_letters.append(extract(post))\n",
    "\n",
    "        pg_num += 1\n",
    "    return titles_letters\n",
    "\n",
    "\n",
    "def scrape_ai_society(base_url):\n",
    "  \n",
    "    response = requests.get(base_url)\n",
    "    data = response.json()\n",
    "    post = data['pageProps']['cmsData']['post']\n",
    "    \n",
    "    return [extract(post)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the titles, images and links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_titles = {}\n",
    "\n",
    "for tag, url in ghost_apis.items():\n",
    "    dct_titles[tag] = scrape_Ghost_API(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-points 58\n",
      "research 359\n",
      "business 173\n",
      "science 75\n",
      "culture 22\n",
      "hardware 28\n",
      "ai-careers 19\n"
     ]
    }
   ],
   "source": [
    "for tag, url in ghost_apis.items():\n",
    "    print(tag, len(dct_titles[tag]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "dct_titles['issues'] = scrape_issues(tag_urls['issues'], 300)\n",
    "print(len(dct_titles['issues']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "print(len(dct_titles['issues']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "dct_titles['letters'] = scrape_letters(tag_urls['letters'])\n",
    "print(len(dct_titles['letters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "dct_titles['ai-society'] = scrape_ai_society(tag_urls['ai-society'])\n",
    "print(len(dct_titles['ai-society']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape articles texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-points\n",
      "research\n",
      "business\n",
      "science\n",
      "culture\n",
      "hardware\n",
      "ai-careers\n",
      "issues\n",
      "letters\n",
      "ai-society\n"
     ]
    }
   ],
   "source": [
    "for i in dct_titles:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in dct_titles:\n",
    "    data[tag] = []\n",
    "    for post in dct_titles[tag]:\n",
    "        # print(title['link'])\n",
    "        reqs = requests.get(post['link'])\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')  \n",
    "        \n",
    "        article_div = soup.find('div', class_=\"prose--styled justify-self-center post_postContent__wGZtc\")\n",
    "\n",
    "# Extract all the text from that div (including both <p> and <li> tags)\n",
    "        if article_div:\n",
    "            article_text = ' '.join([element.get_text() for element in article_div.find_all(['p', 'li'])])\n",
    "            post['text'] = article_text\n",
    "            data[tag].append(post)\n",
    "        else:\n",
    "            print(\"post: \", post)\n",
    "            print(\"Div with the specified class not found\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data.json', 'w') as json_file:\n",
    "    json.dump(dct_titles, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
