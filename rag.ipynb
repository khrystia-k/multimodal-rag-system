{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "metadata": {},
    "ExecuteTime": {
     "end_time": "2024-10-18T12:10:12.682534Z",
     "start_time": "2024-10-18T12:10:12.672744Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "import base64\n",
    "import io\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document, HumanMessage, AIMessage\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading data from file"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:48:49.195887Z",
     "start_time": "2024-10-18T08:48:49.149858Z"
    }
   },
   "source": [
    "with open('raw_data.json', 'r') as file:\n",
    "    data = json.load(file)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:48:56.658009Z",
     "start_time": "2024-10-18T08:48:56.654119Z"
    }
   },
   "source": [
    "def encode_image(image_url: str) -> str:\n",
    "    response = requests.get(image_url)\n",
    "    response.raise_for_status() \n",
    "    return base64.b64encode(response.content).decode('utf-8')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:48:58.416486Z",
     "start_time": "2024-10-18T08:48:58.413925Z"
    }
   },
   "source": [
    "text_elements = []\n",
    "image_elements = []\n",
    "image_links = []\n",
    "link_elements = []\n",
    "title_elements = []"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "metadata": {},
    "ExecuteTime": {
     "end_time": "2024-10-18T08:58:11.187493Z",
     "start_time": "2024-10-18T08:49:00.690032Z"
    }
   },
   "source": [
    "for tag in data:\n",
    "    for article in data[tag]:\n",
    "        text_elements.append(article['text'])\n",
    "        image_links.append(article['feature_image'])\n",
    "        encoded_image = encode_image(article['feature_image'])\n",
    "        image_elements.append(encoded_image)\n",
    "        link_elements.append(article['link'])\n",
    "        title_elements.append(article['title'])\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "metadata": {},
    "ExecuteTime": {
     "end_time": "2024-10-18T08:44:59.242972Z",
     "start_time": "2024-10-18T08:44:59.239207Z"
    }
   },
   "source": [
    "# print(\"The length of title elements are :\", len(title_elements))\n",
    "print(\"The length of text elements are :\", len(text_elements))\n",
    "print(\"The length of image elements are :\",len(image_elements))\n",
    "print(\"The length of link elements are :\", len(link_elements))\n",
    "print(\"The length of title elements are :\", len(title_elements))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of text elements are : 1259\n",
      "The length of image elements are : 1259\n",
      "The length of link elements are : 1259\n",
      "The length of title elements are : 1259\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing data for vector db"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:59:02.810847Z",
     "start_time": "2024-10-18T08:59:02.808052Z"
    }
   },
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1150, chunk_overlap=150)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:59:08.466289Z",
     "start_time": "2024-10-18T08:59:06.761527Z"
    }
   },
   "source": [
    "all_chunks = []\n",
    "original_data_chunks = []\n",
    "\n",
    "for title, article, link in zip(title_elements, text_elements, link_elements):\n",
    "    chunks = text_splitter.split_text(article)\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append(chunk)\n",
    "        original_data_chunks.append([title, link, chunk])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:08:30.509421Z",
     "start_time": "2024-10-15T15:08:30.410693Z"
    }
   },
   "source": [
    "chain_gpt= ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1024)"
   ],
   "outputs": [],
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:08:34.529953Z",
     "start_time": "2024-10-15T15:08:34.525971Z"
    }
   },
   "source": [
    "# Function for image summaries\n",
    "def summarize_image(encoded_image):\n",
    "    prompt = [\n",
    "        AIMessage(content=\"You are a bot that is good at analyzing images.\"),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": \"Describe the contents of this image.\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ])\n",
    "    ]\n",
    "    response = chain_gpt.invoke(prompt)\n",
    "    return response.content"
   ],
   "outputs": [],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:01:48.339621Z",
     "start_time": "2024-10-18T09:01:48.332266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path for saving progress\n",
    "save_path_summaries = 'image_summaries.json'\n",
    "\n",
    "if os.path.exists(save_path_summaries):\n",
    "    with open(save_path_summaries, 'r') as f:\n",
    "        image_summaries = json.load(f)\n",
    "else:\n",
    "    image_summaries = []"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:02:00.204109Z",
     "start_time": "2024-10-18T09:02:00.201344Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(image_summaries))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This part is commented because we already generated image_summaries\n",
    "# def save_progress(summaries):\n",
    "#     with open(save_path_summaries, 'w') as f:\n",
    "#         json.dump(summaries, f)\n",
    "#     \n",
    "# \n",
    "# save_interval = 10\n",
    "# \n",
    "# # Processing images with progress tracking\n",
    "# for i, image in tqdm(enumerate(image_elements, start=len(image_summaries)), \n",
    "#                      total=len(image_elements), desc=\"Processing images\"):\n",
    "#     try:\n",
    "#         image_summary = summarize_image(image)\n",
    "#         image_summaries.append(image_summary)\n",
    "#         \n",
    "#         # Auto-save after a specified interval\n",
    "#         if (i + 1) % save_interval == 0:\n",
    "#             save_progress(image_summaries)\n",
    "#             print(f\"Progress saved at image {i + 1}\")\n",
    "# \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image {i + 1}: {e}\")\n",
    "# \n",
    "# # Final save after the loop ends\n",
    "# save_progress(image_summaries)\n",
    "# print(\"Final progress saved.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating vector database\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:59:31.025435Z",
     "start_time": "2024-10-18T08:59:30.677302Z"
    }
   },
   "source": [
    "# Initialize the vector store and storage layer\n",
    "vectorstore = Chroma(collection_name=\"sources\", embedding_function=OpenAIEmbeddings())\n",
    "store = InMemoryStore()\n",
    "id_key = \"article_id\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:59:38.639166Z",
     "start_time": "2024-10-18T08:59:38.636613Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=id_key)",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:01:03.772562Z",
     "start_time": "2024-10-18T08:59:49.261589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add text chunks\n",
    "text_ids = [str(uuid.uuid4()) for _ in all_chunks]\n",
    "text_docs = [\n",
    "    Document(\n",
    "        page_content=text, \n",
    "        metadata={\n",
    "            id_key: text_ids[i]\n",
    "        }\n",
    "    )\n",
    "    for i, text in enumerate(all_chunks)\n",
    "]\n",
    "\n",
    "original_text_docs = [Document(\n",
    "    page_content = original_data_chunks[i][2],\n",
    "    metadata={\n",
    "       \"type\": 'text',\n",
    "       \"title\": original_data_chunks[i][0],  \n",
    "        \"link\": original_data_chunks[i][1]    \n",
    "        }\n",
    "    )\n",
    "    for i in range(len(original_data_chunks))\n",
    "]\n",
    "# Add the documents to the vectorstore\n",
    "retriever.vectorstore.add_documents(text_docs)\n",
    "# Store the original chunks (document content) in the docstore\n",
    "retriever.docstore.mset(\n",
    "    [(text_ids[i], original_text_docs[i]) for i in range(len(all_chunks))]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:02:15.808553Z",
     "start_time": "2024-10-18T09:02:05.403816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Add images\n",
    "image_ids = [str(uuid.uuid4()) for _ in image_summaries]\n",
    "image_docs = [\n",
    "    Document(\n",
    "        page_content=summary,  # Image summary or description\n",
    "        metadata={\n",
    "            id_key: image_ids[i] \n",
    "        }\n",
    "    )\n",
    "    for i, summary in enumerate(image_summaries)\n",
    "]\n",
    "\n",
    "original_image_docs = [Document(\n",
    "    page_content=image, \n",
    "    metadata={\n",
    "        \"type\": 'image',\n",
    "        'link': image_links[i]\n",
    "    }\n",
    "    )\n",
    "    for i, image in enumerate(image_elements)\n",
    "]\n",
    "\n",
    "# Add the documents to the vectorstore\n",
    "retriever.vectorstore.add_documents(image_docs)\n",
    "# Store the original images in the docstore\n",
    "retriever.docstore.mset(\n",
    "    [(image_ids[i], original_image_docs[i]) for i in range(len(image_summaries))]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementing RAG"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:43:54.868030Z",
     "start_time": "2024-10-18T10:43:54.863386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_context(retrieved_docs : str):\n",
    "    context = ''\n",
    "    for doc in retrieved_docs:\n",
    "        if doc.metadata['type'] == 'text':\n",
    "            context+= doc.page_content\n",
    "            context += '\\n\\n'\n",
    "\n",
    "    if len(context) > 128000:\n",
    "        context = context[:12800]\n",
    "    return context\n"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T11:40:08.752815Z",
     "start_time": "2024-10-18T11:40:08.664302Z"
    }
   },
   "source": [
    "template = \"\"\" You are part of a system that answer questions and search relevant articles and images. \n",
    "\n",
    "Your task: Answer the question based only on the following context, which can include only text.\\\n",
    "           If you don't know than answer: \"It is better to look at retrieved artickles or images.\"\\n\\nContext: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | RunnableLambda(prepare_context) , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T11:40:09.304499Z",
     "start_time": "2024-10-18T11:40:09.299464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wrapper function for Gradio UI\n",
    "def wrapper_func(query):\n",
    "    \n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    response = chain.invoke(query)\n",
    "    \n",
    "    text_results = []\n",
    "    images = []\n",
    "    seen_images = set()\n",
    "    \n",
    "    for doc in retrieved_docs:\n",
    "        if doc.metadata['type'] == 'text':\n",
    "            title = doc.metadata.get('title', 'Untitled')\n",
    "            link = doc.metadata.get('link', 'No link available')\n",
    "            content = doc.page_content\n",
    "            text_results.append(f\"**Title:** {title}\\n\\n**Link:** {str(link)}\\n\\n**Citation:** {content}\")\n",
    "        elif doc.metadata['type'] == 'image':\n",
    "            image_data = base64.b64decode(doc.page_content)\n",
    "            if image_data not in seen_images:\n",
    "                seen_images.add(image_data)\n",
    "                images.append(Image.open(io.BytesIO(image_data)))\n",
    "            \n",
    "    text_output = \"\\n\\n---\\n\\n\".join(text_results)\n",
    "    return response, text_output, images"
   ],
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:04:11.052422Z",
     "start_time": "2024-10-18T12:04:10.398229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Building UI with Gradio\n",
    "with gr.Blocks(theme=gr.themes.Ocean()) as ui:\n",
    "    gr.Markdown(\"# Multimodal RAG System Demo ðŸ¤–\")\n",
    "    \n",
    "    query_input = gr.Textbox(label=\"Enter your question\", lines=2, placeholder=\"Ask me something...\")\n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "    answer_output = gr.Textbox(label=\"Answer\", lines=5, interactive=False)\n",
    "    text_output = gr.Markdown(label=\"Retrieved Articles\")\n",
    "    image_output = gr.Gallery(label=\"Retrieved Images\", elem_id=\"gallery\")\n",
    "\n",
    "    submit_btn.click(\n",
    "        fn=wrapper_func,\n",
    "        inputs=query_input,\n",
    "        outputs=[answer_output, text_output, image_output]\n",
    "    )\n",
    "    \n",
    "ui.launch()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7921\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7921/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T11:13:02.016357Z",
     "start_time": "2024-10-18T11:13:00.352928Z"
    }
   },
   "source": [
    "query = 'What is O1-engineer ?'\n",
    "print(chain.invoke(query))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O1-engineer is a command-line tool that uses OpenAIâ€™s API to assist developers with code generation, file management, project planning, and code review. It features an interactive console, conversation history management, and enhanced file and folder operations to help streamline development workflows. Additionally, O1-engineer can automate routine tasks and provide intelligent support throughout the development process.\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:42:50.225776Z",
     "start_time": "2024-10-18T10:42:49.827001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "print('Type: ', type(retrieved_docs))\n",
    "print('len: ', len(retrieved_docs))"
   ],
   "outputs": [],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
